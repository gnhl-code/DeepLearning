{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90b0ca1",
   "metadata": {},
   "source": [
    "# Laboratory Task 4\n",
    "\n",
    "Genheylou Felisilda - DS4A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17058a18",
   "metadata": {},
   "source": [
    "Instruction: Train a linear regression model in PyTorch using a regression dataset. Use the following parameters. <br>\n",
    "\n",
    "- Criterion: MSE Loss\n",
    "- Fully Connected Layers x 2\n",
    "- Batch Size: 8\n",
    "- Optimizer: SGD\n",
    "- Epoch: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42962973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c41b01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea11165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to PyTorch tensors\n",
    "\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9403f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader with batch size of 8\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a8d0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model with 2 fully connected layers\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First FC layer\n",
    "        self.fc2 = nn.Linear(64, 1)           # Second FC layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = LinearRegressionModel(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df9de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define MSE loss and SGD optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad9803de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 871.7837\n",
      "Epoch [200/1000], Loss: 4940.1992\n",
      "Epoch [300/1000], Loss: 5618.7051\n",
      "Epoch [400/1000], Loss: 11855.5898\n",
      "Epoch [500/1000], Loss: 11633.8916\n",
      "Epoch [600/1000], Loss: 3377.8555\n",
      "Epoch [700/1000], Loss: 914.1067\n",
      "Epoch [800/1000], Loss: 448.6788\n",
      "Epoch [900/1000], Loss: 26477.8789\n",
      "Epoch [1000/1000], Loss: 2250.0264\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# train for 1000 epochs\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3675ba",
   "metadata": {},
   "source": [
    "Loss is fluctuating significantly\n",
    " The loss jumps up and down across epochs rather than steadily decreasing. This indicates that the network is not converging properly and the learning process is unstable.\n",
    "\n",
    "Potential causes of instability:\n",
    "- Randomness of data processing\n",
    "- Learning rate might be too high, causing the weights to overshoot the minimum.\n",
    "- The network architecture or initialization may not be suitable for the data.\n",
    "- The dataset might be small or noisy, making it hard for the network to find a consistent pattern.\n",
    "- Training is not effective: After 1000 epochs, the loss is still very high, which implies the network has not learned to approximate the target outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
