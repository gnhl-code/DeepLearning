{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61480b13-c28c-4175-83a1-1ae26ccaac23",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Times New Roman\"><strong>II . Understanding Deep Learning</strong></h3>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">Having explored the historical background and inspiration behind deep learning, we can now delve into understanding the underlying mechanisms of this seemingly sci-fi technology. This journey will uncover how deep learning works, including the foundational concepts, methodologies, and real-world applications that make it a transformative force in modern technology.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c651a-76a6-42a3-9122-a86599e25455",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>Artificial Neural Network</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f6bd5-2007-43b1-ad4c-05f7f3ae6030",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">Artificial Neural Networks (ANNs) consist of artificial neurons, known as <b>units</b>, organized into layers that form the entire network. These layers can range from having a few dozen units to millions, depending on the complexity required to learn hidden patterns in the data. Typically, an ANN includes an <b>input layer</b>, one or more <b>hidden layers</b>, and an <b>output layer</b>. The input layer receives external data for analysis, which is then processed through the hidden layers that transform the input into valuable information for the output layer. The output layer then generates a response based on the processed data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9dcf16-6e96-4267-85de-a61541d067ab",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"figures/example1.png\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ac8dd-ea09-4791-a24c-81d58c97dfb8",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">In most neural networks, units in different layers are interconnected, with each connection having a weight that determines the influence of one unit on another. As data flows through these connections, the neural network progressively learns from the data, ultimately producing an output from the output layer. </br > </br >Artificial neural networks are trained using a dataset. To teach an ANN to recognize a cat, it is presented with thousands of different cat images. The network learns to identify cats by analyzing these images. Once trained, the ANN is tested by classifying new images and determining whether they are cat images or not. The output is compared to a human-provided label. If the ANN misclassifies an image, backpropagation is used to refine the network's weights based on the error rate. This process iterates until the ANN can accurately recognize cat images with minimal errors.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c95a67-98c5-456a-a8e1-8891c16e78db",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>Feedforward Neural Network</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0040130-9c35-4556-9f10-194842bda3b5",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">The feedforward neural network is one of the most basic artificial neural networks. In this ANN, the data or the input provided travels in a single direction. It enters into the ANN through the input layer and exits through the output layer while hidden layers may or may not exist. So the feedforward neural network has a front-propagated wave only and usually does not have backpropagation.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c419c-dcac-4a82-85c0-043325155167",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    Assume that the neurons have a <b>sigmoid</b> activation function, perform a forward pass on the network. Assume that the actual output of $y$ is 1 and <b>learning rate</b> $\\alpha$ is 0.9.\n",
    "<br>\n",
    "To calculate $H_1$, we need to calculate first the weighted sum of the input values added by the bias $\\theta$.\n",
    "<br>\n",
    "$$Z = \\sum_j{(w_{i,j} \\cdot x_i)} + \\theta_i$$\n",
    "$Z_1 = (w_{11} \\cdot x_1) + (w_{13} \\cdot x_2) + (w_{15} \\cdot x_3) + \\theta_1$\n",
    "<br>\n",
    "$Z_2 = (w_{12} \\cdot x_1) + (w_{14} \\cdot x_2) + (w_{16} \\cdot x_3) + \\theta_2$\n",
    "<br>\n",
    "<br>\n",
    "After computing the <b>weighted sum</b>, we introduce non-linearity to the output result by applying a nonlinear function. For this example, let's use <b>sigmoid function</b>.\n",
    "<br>\n",
    "$$\\sigma = \\frac{1}{1+e^{-Z_i}}$$\n",
    "$H_1 = \\sigma(Z_1)$\n",
    "<br>\n",
    "$H_2 = \\sigma(Z_2)$\n",
    "<br>\n",
    "<br>\n",
    "Now that we have computed the hidden layer's value, we can now proceed to computing the weighted sum for the output layer using the same procedure as how we compute the $Z_n$ and $H_n$.\n",
    "<br>\n",
    "<br>\n",
    "$Z_3 = (w_{21} \\cdot H_1) + (w_{22} \\cdot H_2) + \\theta_3$\n",
    "<br>\n",
    "$\\hat{y} = \\sigma(Z_3)$\n",
    "<br>\n",
    "<br>\n",
    "This is how the calculations in a feedforward neural network are traversed from input to output.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdcdf36-2e6e-4630-9ae7-4b343f0bdb8f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-family: Times New Roman\">\n",
    "    <h4><strong>Laboratory Task 2</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <b>Instruction:</b> Perform a single forward pass and compute for the error.\n",
    "</p>\n",
    "\n",
    "$$x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$y = \\begin{bmatrix} 1 \\end{bmatrix}$$\n",
    "\n",
    "$$f=max(0, Z_n)$$\n",
    "\n",
    "$$\\text{hidden unit weights} = \n",
    "\\begin{bmatrix}\n",
    "w_{11} = 0.2 && w_{12} = -0.3 \\\\\n",
    "w_{13} = 0.4 && w_{14} = 0.1 \\\\\n",
    "w_{15} = -0.5 && w_{16} = 0.2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\\text{output unit weights} = \n",
    "\\begin{bmatrix}\n",
    "w_{21} = -0.3 \\\\\n",
    "w_{22} = -0.2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_{1} = -0.4 \\\\\n",
    "\\theta_{2} = 0.2 \\\\\n",
    "\\theta_{3} = 0.1\n",
    "\\end{bmatrix}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2b12e-91eb-4d79-a499-6c53a433f7a9",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>Backward Propagation of Errors</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49fc67-55b2-4bbb-b17f-d5f49a1e54d6",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">Backward propagation a.k.a backprop or backward pass is a fundamental algorithm used for training artificial neural networks. It involves a two-step process: a forward pass and a backward pass. During the forward pass, input data is fed through the network, and the output is generated. The error, or the difference between the predicted output and the actual target, is then calculated. In the backward pass, this error is propagated back through the network, layer by layer, to update the weights and biases. This is done by computing the gradient of the loss function with respect to each weight using the chain rule of calculus. By iteratively adjusting the weights in the direction that reduces the error, backpropagation helps the network learn and improve its performance over time. This process continues until the network's predictions are sufficiently accurate or another stopping criterion is met.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b584a6-1fa0-4649-87ba-934afaee7155",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "The initial value for $\\hat{y}$ is not the optimal value since the parameters used were just randomly selected. Therefore, after the forward propagation, a backward propagation algorithm is employed to update the parameters ($w$ and $\\theta$).\n",
    "<br>\n",
    "The error at the output layer is calculated as the difference between the predicted output ($\\hat{y}$) and the actual output ($y$):\n",
    "<br>\n",
    "$$\\delta = \\hat{y} - y$$\n",
    "<br>\n",
    "Compute Hidden Layer Error ($\\delta_h$)\n",
    "<br>\n",
    "$$\\delta_h = (\\delta_o W^T_o) \\cdot \\sigma'(Z_h)$$\n",
    "<br>\n",
    "Where:\n",
    "<br>\n",
    "<ul style=\"font-family:Times New Roman\">\n",
    "    <li> $\\sigma'(Z_h)$ is the derivative of the sigmoid activation function applied to the hidden layer activations $Z_h$:</li>\n",
    "    <li> $\\sigma'(Z_h) = A_h \\cdot (1 - A_h)$</li>\n",
    "    <li> $W^T_o$ is the transpose of the output weights matrix $W_o$.</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Calculate Gradients\n",
    "<br>\n",
    "Once we have the errors ($\\delta_o$ and $\\delta_h$), we compute the gradients of the error with respect to the weights ($W_o$ and $W_h$).\n",
    "<br>\n",
    "Gradients for Output Layer Weights ($\\frac{\\partial E}{\\partial W_o}$)\n",
    "<br>\n",
    "$$\\frac{\\partial E}{\\partial W_o} = A\\frac{T}{h} \\delta_o$$\n",
    "<br>\n",
    "Gradients for Hidden Layer Weights ($\\frac{\\partial E }{\\partial W_h}$)\n",
    "<br>\n",
    "$$\\frac{\\partial E}{\\partial W_h} = X^T \\delta_h$$\n",
    "<br>\n",
    "Finally, the weights are updated using the gradients and the learning rate ($\\alpha$).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a3b68-4576-46a5-8a00-6d3d1efed26b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-family: Times New Roman\">\n",
    "    <h4><strong>Laboratory Task 3</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <b>Instruction:</b> Perform a forward and backward propagation in python using the inputs from <b>Laboratory Task 2</b>\n",
    "</p>\n",
    "\n",
    "```python\n",
    "x = np.array([1, 0, 1])\n",
    "y = np.array([1])\n",
    "\n",
    "# use relu as the activation function.\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c267e00-1ed6-4b14-9f6b-aa8159e6e948",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>Introduction to PyTorch</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3753f-b633-4595-94e8-e814c769a30b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png?20211003060202\" width=\"15%\"></center>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">PyTorch is a powerful and widely-used open-source framework for deep learning, developed by Facebook's AI Research lab. It is designed to provide flexibility and speed for both research and production environments. PyTorch's primary strength lies in its dynamic computation graph, which allows for real-time changes and debugging, making it easier to experiment with new ideas. This is in contrast to static computation graphs used by other frameworks like TensorFlow. PyTorch supports a range of applications, from natural language processing to computer vision, through its extensive library of pre-built modules and tools. Additionally, its integration with Python makes it accessible to a large community of developers and researchers, fostering rapid development and collaboration. With a strong emphasis on simplicity and performance, PyTorch has become a go-to tool for many in the deep learning community.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2612b-1d75-47cb-9b37-2406306ff083",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>Setting up the Virtual Enviroment</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09feea2f-7f9c-4a57-b1b3-ba7790f9836d",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">A virtual environment is a self-contained directory that isolates a specific Python environment, allowing users to manage dependencies and packages for different projects independently. This ensures that each project can have its own unique set of libraries and versions without conflicts, avoiding issues that arise from global installations. Virtual environments are particularly useful for maintaining consistent development environments, making it easier to manage project-specific dependencies and ensuring that applications run smoothly across different setups. Tools like <b>venv</b> and <b>virtualenv</b> facilitate the creation and management of these environments. We can create a virtual environment using either <b>pip</b> or <b>conda</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187cf0fd-d197-46d5-a88a-c0163b873aa7",
   "metadata": {},
   "source": [
    "<ol style=\"font-family:Times New Roman; font-size:15px\">\n",
    "    <strong><li>With PIP</li></strong>\n",
    "    <ul>\n",
    "        <li>Make sure that you have installed python and have its directory path added in the machine's environment variables.</li>\n",
    "        <li>Create a new folder, make sure that you know the directory of the new folder that you have created.</li>\n",
    "        <li>Open command prompt and change the directory to the new folder that you created.</li>\n",
    "        <li>Considering that you already have configured pip in the environment variables, you can now install libraries.</li>\n",
    "        <li>Run command <div class=\"custom-inline-code\" class=\"cd\">pip install virtualenv</div>.</li>\n",
    "        <li>You can create a virtual enviroment with a specific python version but only if the specific version is installed in your system.</li>\n",
    "        <li>Run command <div class=\"custom-inline-code\">virtualenv -p /path/to/pythonX.X /path/to/new/virtual/environment</div></li>\n",
    "        <li>Replace <div class=\"custom-inline-code\">/path/to/pythonX.X</div> with the path to the desired Python executable (e.g., <div class=\"custom-inline-code\">/usr/bin/python3.8</div>) and <div class=\"custom-inline-code\">/path/to/new/virtual/environment</div> with the path where you want to create the virtual environment.</li>\n",
    "        <li>Activate the virtual environment, make sure that you are inside the directory where the environment's folder is also under.</li>\n",
    "        <li>Run command <div class=\"custom-inline-code\">env_name/Scripts/activate</div>.</li>\n",
    "        <li>Replace <div class=\"custom-inline-code\">env_name</div> with the name of the environment you created.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <strong><li>With CONDA</li></strong>\n",
    "    <ul>\n",
    "        <li>Make sure that <a href=\"https://www.anaconda.com/\">anaconda</a> is installed in you system.</li>\n",
    "        <li>Open anaconda prompt and run command <div class=\"custom-inline-code\">conda create -n <myenv> python=3.X</div></li>\n",
    "        <li>Activate the environment by running the command <div class=\"custom-inline-code\">conda activate env_name</div>.</li>\n",
    "        <li>Replace <div class=\"custom-inline-code\">env_name</div> with the name of the environment you created.</li>\n",
    "    </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53549bf0-37cc-4ee5-8d89-a781cd79303f",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>PyTorch Installation</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11d891-1d44-443d-9e74-7a67085bd0c4",
   "metadata": {},
   "source": [
    "<ol style=\"font-family: Times New Roman; font-size:15px\">\n",
    "    <li>Make sure that python is installed in your local device, the stable version of pytorch runs on python version 3.6 to 3.9. Make sure that your python version is in between this range. You can check the python version using command the command;</li>\n",
    "    <br>\n",
    "    <div class=\"custom-alert\">\n",
    "        <div class=\"custom-code\">python --version</div>\n",
    "    </div>\n",
    "    <br>\n",
    "    <li>Activate the virtual environment, for this demonstration, let's just use the conda virtual enviroment.</li>\n",
    "    <br>\n",
    "    <div class=\"custom-alert\">\n",
    "        <div class=\"custom-code\">conda activate env_name</div>\n",
    "    </div>\n",
    "    <br>\n",
    "    <li>Go to <a href=\"https://pytorch.org/get-started/locally/\">https://pytorch.org/get-started/locally/</a> and select appropriate machine configurations and copy the generated command. <br> If you have a CUDA enabled GPU, you can download and install CUDA toolkit version 11.8 or 12.1 first. Otherwise you may only select CPU.</li>\n",
    "    <br>\n",
    "    <center><img src=\"figures/torch.png\" width=\"600px\"></center>\n",
    "    <br>\n",
    "    <li>Paste the command in the anaconda prompt where you activated the virtual enviroment and wait patiently. <br> Just click <div class=\"custom-inline-code\">Y</div> when prompted with a question to proceed installation.</li>\n",
    "    <br>\n",
    "    <center><img src=\"figures/torch2.png\" width=\"600px\"></center>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c575baf-5136-4555-878a-05001bbd7a3d",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>PyTorch Components</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">Let's have linear regression as a case study to study the different components of PyTorch.  These are the following components we will be covering:</p>\n",
    "\n",
    "<ol style=\"font-family: Times New Roman; font-size:15px\">\n",
    "    <li>Specifying input and target</li>\n",
    "    <li>Dataset and DataLoader</li>\n",
    "    <li><div class=\"custom-inline-code\">nn.Linear</div> (Dense) </li>\n",
    "    <li>Define loss function</li>\n",
    "    <li>Define optimizer function</li>\n",
    "    <li>Train the model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf2cf4-0801-49a8-9160-794ff6548a39",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    Consider this data:\n",
    "    <br>\n",
    "    <img src=\"figures/japan.png\" class=\"center\" width=\"60%\">\n",
    "    <br>\n",
    "    In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "    <br>\n",
    "    <br>\n",
    "$$\\text{yield}_\\text{apple}  = w_{11} \\cdot \\text{temp} + w_{12} \\cdot \\text{rainfall} + w_{13} \\cdot \\text{humidity} + b_{1}$$\n",
    "$$\\text{yield}_\\text{orange} = w_{21} \\cdot \\text{temp} + w_{22} \\cdot \\text{rainfall} + w_{23} \\cdot \\text{humidity} + b_{2}$$\n",
    "    <br>\n",
    "    Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
    "    <br>\n",
    "    <img src=\"figures/japan2.png\" class=\"center\" width=\"60%\">\n",
    "    <br>\n",
    "    The learning part of linear regression is to figure out a set of weights <strong>w11, w12,... w23, b1 & b2</strong> using gradient descent.\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfd2d1-a7f2-4047-bfb0-1db2b79c1ad0",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>Sample Implementation</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406ec854-d948-43d3-825c-aff28a5d9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da0d26f-e860-4306-adb9-18e7e5f00d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c0fcf4-c0ef-4898-8588-cfbc5a6bd241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61aee8f-5e79-4f15-8a32-d07e769d2418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73205fa-5985-44e1-9914-b553511803ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#We can check whether we have gpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c5e8c-0c1d-4e3a-b228-1cca39b3db15",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>1. Specifiying input and target</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4899f40b-e992-4d37-8583-e5e55a1ca54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "x_train = np.array([\n",
    "    [73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "    [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "    [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "    [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "    [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                   dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "y_train = np.array([\n",
    "    [56, 70], [81, 101], [119, 133], \n",
    "    [22, 37], [103, 119], [56, 70], \n",
    "    [81, 101], [119, 133], [22, 37], \n",
    "    [103, 119], [56, 70], [81, 101], \n",
    "    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f174f12e-0f2d-4d1b-b2ac-792f31968411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3])\n",
      "torch.Size([15, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(x_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "print(inputs.size())\n",
    "print(targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce9b94-98c4-46ba-9aa6-6a1d1454d21f",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>2. Dataset and DataLoader</strong></p>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    PyTorch provides two data primitives: <a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><strong><tt>torch.utils.data.DataLoader</tt></strong></a> and <a href=\"https://pytorch.org/vision/0.18/datasets.html\"><strong><tt>torch.utils.data.Dataset</tt></strong></a> that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683a36e8-21ab-4688-aa72-88c50169e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de216e2-6963-4a9c-ae38-b409b6bf9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203b458-656d-405e-b1fc-35508175a8a9",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    We'll now create a <strong><tt>DataLoader</tt></strong>, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aae761c-fc6e-407c-bd73-9229cdbcd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e6c06d-34c9-4c95-9e6d-5e67206de476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eacd501c-676a-4ab9-b9cc-b002ada201a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025614e-0a2e-42cf-8a43-4d08e4e16423",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "The <strong><tt>DataLoader</tt></strong> is typically used in a for-in loop. Let's look at an example\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd779e42-890a-4cf8-93e1-281caaa8554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [119., 133.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985291b-0123-4ed3-ba84-6dbfb6263421",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    In each iteration, the data loader returns one batch of data, with the given batch size. If shuffle is set to True, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, which can lead to faster reduction in the loss.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60763fc-3a2e-4f27-aa31-829f2ec3b32d",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>3. Define some Layer - <strong><tt>nn.Linear</tt></strong></strong></p>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Instead of initializing the weights & biases manually, we can define the model using the <strong><tt>nn.Linear</tt></strong> class from PyTorch, which does it automatically.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bed9f9b-95db-4aa9-bbd1-1733f6ef4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7cbecad-ad7d-4f6b-a9aa-9452216dd0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4414,  0.4792, -0.1353],\n",
      "        [ 0.5304, -0.1265,  0.1165]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([-0.2811,  0.3391], requires_grad=True)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "seed_everything()\n",
    "model = nn.Linear(3, 2)  #nn.Linear assume this shape (in_features, out_features)\n",
    "print(model.weight)\n",
    "print(model.weight.size()) # (out_features, in_features)\n",
    "print(model.bias)\n",
    "print(model.bias.size()) #(out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac343946-9ea0-464a-a56a-63e2c3456b35",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "In fact, our model is simply a function that performs a matrix multiplication of the <strong><tt>inputs</tt></strong> and the weights <strong><tt>w</tt></strong> and adds the bias <strong><tt>b</tt></strong> (for each observation)\n",
    "<br>\n",
    "<img src = \"figures/dot.png\" class=\"center\" width=\"60%\">\n",
    "<br>\n",
    "PyTorch models also have a helpful <strong><tt>.parameters</tt></strong> method, which returns a list containing all the weights and bias matrices present in the model. For our linear regression model, we have one weight matrix and one bias matrix.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67b38f0f-8260-4d8f-9828-44ae6b445a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.4414,  0.4792, -0.1353],\n",
       "         [ 0.5304, -0.1265,  0.1165]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2811,  0.3391], requires_grad=True)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(model.parameters())  #model.param returns a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6f60735-d6db-4528-9d26-e909d02c9127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8c3bf-db40-4bca-a79d-7e2cc1879675",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "We can use the <strong><tt>model(tensor)<tt></strong> API to perform a forward-pass that generate predictions.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef30ff80-b7f3-4c87-a4fd-b29faa249986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[58.2323, 35.5896],\n",
       "        [73.4005, 44.9262],\n",
       "        [94.4899, 36.2867],\n",
       "        [60.3437, 53.3070],\n",
       "        [66.7117, 32.9453],\n",
       "        [58.2323, 35.5896],\n",
       "        [73.4005, 44.9262],\n",
       "        [94.4899, 36.2867],\n",
       "        [60.3437, 53.3070],\n",
       "        [66.7117, 32.9453],\n",
       "        [58.2323, 35.5896],\n",
       "        [73.4005, 44.9262],\n",
       "        [94.4899, 36.2867],\n",
       "        [60.3437, 53.3070],\n",
       "        [66.7117, 32.9453]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5686801-d3eb-4f73-8a58-7a14c03e7f82",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>4. Define Loss Function</strong></p>\n",
    "\n",
    "The <strong><tt>nn<tt></strong> module contains a lot of useful loss function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "123595b6-6911-4c19-b31e-23250a967a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_mse = nn.MSELoss()\n",
    "criterion_softmax_cross_entropy_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea933137-bbf9-4d55-8d84-6063094ba50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2480.3708, grad_fn=<MseLossBackward0>)\n",
      "2480.370849609375\n"
     ]
    }
   ],
   "source": [
    "mse = criterion_mse(preds, targets)\n",
    "print(mse)\n",
    "print(mse.item())  ##print out the loss number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d75106-cc20-4d59-a541-8c11469a877c",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>5. Define the Optimizer</strong></p>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "We use  <strong><tt>optim.SGD</tt></strong> to perform stochastic gradient descent where samples are selected in batches (often with random shuffling) instead of as a single group.  Note that  <strong><tt>model.parameters()</tt></strong> is passed as an argument to <strong><tt>optim.SGD</tt></strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b179ab48-eab1-47cf-8c9f-1990459e0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "#momentum update the weight based on past gradients also, which will be useful for getting out of local max/min\n",
    "#If our momentum parameter was $0.9$, we would get our current grad + the multiplication of the gradient \n",
    "#from one time step ago by $0.9$, the one from two time steps ago by $0.9^2 = 0.81$, etc.\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c452df-731e-4191-a806-b125850b8c54",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\"><strong>6. Training - Putting Everything Together</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41f55108-e1fb-4158-942b-5c60a10b5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            xb.to(device) #move them to gpu if possible, if not, it will be cpu\n",
    "            yb.to(device)\n",
    "                    \n",
    "            # 1. Predict\n",
    "            pred = model(xb)\n",
    "                      \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Calculate gradient\n",
    "            opt.zero_grad()  #if not, the gradients will accumulate\n",
    "            loss.backward()\n",
    "            \n",
    "            # Print out the gradients.\n",
    "            # print ('dL/dw: ', model.weight.grad) \n",
    "            # print ('dL/db: ', model.bias.grad)\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            sys.stdout.write(\"\\rEpoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83bcc35c-91e7-47f9-a16f-555dac84c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.97430"
     ]
    }
   ],
   "source": [
    "#train for 100 epochs\n",
    "fit(100, model, criterion_mse, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8873c022-94c0-4a7e-94c4-969da073aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9544596672058105\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "loss = criterion_mse(preds, targets)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c05b90b-5b00-4108-8a21-5d124d0a5ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 54.2758,  71.3443],\n",
       "        [ 79.3255, 101.8269],\n",
       "        [113.9149, 134.4432],\n",
       "        [ 17.1712,  38.2095],\n",
       "        [100.2865, 120.0920],\n",
       "        [ 54.2758,  71.3443],\n",
       "        [ 79.3255, 101.8269],\n",
       "        [113.9149, 134.4432],\n",
       "        [ 17.1712,  38.2095],\n",
       "        [100.2865, 120.0920],\n",
       "        [ 54.2758,  71.3443],\n",
       "        [ 79.3255, 101.8269],\n",
       "        [113.9149, 134.4432],\n",
       "        [ 17.1712,  38.2095],\n",
       "        [100.2865, 120.0920]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "297e1f82-dd9e-4e21-ab2b-7f0bf512252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3655e-6e5a-4adb-a3d1-70e964d7e419",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-family: Times New Roman\">\n",
    "    <h4><strong>Laboratory Task 4</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <b>Instruction:</b> Train a linear regression model in PyTorch using a regression dataset. Use the following parameters.\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Criterion: MSE Loss</li>\n",
    "    <li>Fully Connected Layers x 2</li>\n",
    "    <li>Batch Size: 8</li>\n",
    "    <li>Optimizer: SGD</li>\n",
    "    <li>Epoch: 1000</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1088f4-cc2c-4934-bf02-0e54d013a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
