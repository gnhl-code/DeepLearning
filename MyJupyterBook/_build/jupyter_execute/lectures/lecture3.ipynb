{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5272e30-7ca5-487f-9ca5-cb469dbcf65d",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Times New Roman\"><strong>PyTorch Tensor Objects Attributes and Methods</strong></h3>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <br>\n",
    "    This will cover the following operations of a tensor object:\n",
    "    <ul style=\"font-family: Times New Roman; font-size:15px\">\n",
    "        <li>Converting NumPy arrays to PyTorch tensors</li>\n",
    "        <li> Creating tensors from scratch</li>\n",
    "        <li>Indexing and slicing</li>\n",
    "        <li>Reshaping tensors (tensor views)</li>\n",
    "        <li>Tensor arithmetic and basic operations</li>\n",
    "        <li>Dot products</li>\n",
    "        <li>Matrix multiplication</li>\n",
    "        <li>Additional, more advanced operations</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708eb49-8735-47cc-99d8-3339745140db",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/tensor.png\" class=\"center\" width=\"50%\"></center>\n",
    "<br>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters. Tensors are similar to NumPy’s ndarrays, <b>except that tensors can run on GPUs or other specialized hardware to accelerate computing</b>. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bc0ba-067b-4770-a886-f799dd147b33",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>1. Converting NumPy arrays to PyTorch tensors</strong></h4>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "A torch.Tensor is a multi-dimensional matrix containing elements of a single data type. Calculations between tensors can only happen if the tensors share the same dtype. In some cases tensors are used as a replacement for NumPy to use the power of GPUs (more on this later). Let's try to initialize a numpy array first!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b346ebd0-8509-40e1-b003-e8ff8055a1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afd53e9-7ae7-4713-bb7a-6fb7dedcaaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5.]\n",
      "float64\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1,2,3,4,5]).astype('float64')\n",
    "print(arr)\n",
    "print(arr.dtype)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ce8fb9-a8d3-4151-bcfe-e07cc12a1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(arr)\n",
    "# Equivalent to x = torch.as_tensor(arr)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e373a6f-6693-4e63-9435-e8e42264ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Print the datatype\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af16b57-a32b-4fd6-9559-b122614d5195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "# Print the tensor object type\n",
    "print(type(x))\n",
    "print(x.type()) # this is more specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f442ff-e6ff-4c66-b5ed-c37ec094eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]\n",
      " [ 6.  7.  8.]\n",
      " [ 9. 10. 11.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "arr2 = np.arange(0.,12.).reshape(4,3)\n",
    "print(arr2)\n",
    "print(type(arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e13160e-9af7-421b-afc5-437b9ae96678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]], dtype=torch.float64)\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.from_numpy(arr2)\n",
    "print(x2)\n",
    "print(x2.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f99612-7461-4180-9947-f1208ca541ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.635 0.305 0.433 0.088 0.728]\n",
      " [0.261 0.629 0.377 0.029 0.192]\n",
      " [0.279 0.234 0.922 0.404 0.794]\n",
      " [0.645 0.888 0.575 0.37  0.645]\n",
      " [0.441 0.149 0.767 0.1   0.792]]\n",
      "<class 'numpy.matrix'>\n",
      "tensor([[0.6350, 0.3050, 0.4330, 0.0880, 0.7280],\n",
      "        [0.2610, 0.6290, 0.3770, 0.0290, 0.1920],\n",
      "        [0.2790, 0.2340, 0.9220, 0.4040, 0.7940],\n",
      "        [0.6450, 0.8880, 0.5750, 0.3700, 0.6450],\n",
      "        [0.4410, 0.1490, 0.7670, 0.1000, 0.7920]], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "rows, cols = 5, 5\n",
    "\n",
    "# Create matrix using array comprehension\n",
    "mat = np.matrix([[np.round(np.random.random(), 3) for _ in range(cols)] for _ in range(rows)])\n",
    "print(mat)\n",
    "print(type(mat))\n",
    "\n",
    "\n",
    "xmat = torch.from_numpy(mat)\n",
    "print(xmat)\n",
    "print(type(xmat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aefaf73-a577-4563-909f-e15046240234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if an object is a tensor\n",
    "torch.is_tensor(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061dc64-57aa-4d25-b9f4-5d7692d4dbac",
   "metadata": {},
   "source": [
    "<table style=\"font-family: Times New Roman\">\n",
    "    <tr>\n",
    "        <th colspan=\"4\"><a href=\"https://pytorch.org/docs/stable/tensors.html\"><h3>Tensor Datatypes</h3></a></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>TYPE</b></td>\n",
    "        <td><b>NAME</b></td>\n",
    "        <td><b>EQUIVALENT</b></td>\n",
    "        <td><b>TENSOR TYPE</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>32-bit integer (signed)</td>\n",
    "        <td>torch.int32</td>\n",
    "        <td>torch.int</td>\n",
    "        <td>IntTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>64-bit integer (signed)</td>\n",
    "        <td>torch.int64</td>\n",
    "        <td>torch.long</td>\n",
    "        <td>LongTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>16-bit integer (signed)</td>\n",
    "        <td>torch.int16</td>\n",
    "        <td>torch.short</td>\n",
    "        <td>ShortTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>32-bit floating point</td>\n",
    "        <td>torch.float32</td>\n",
    "        <td>torch.float</td>\n",
    "        <td>FloatTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>64-bit floating point</td>\n",
    "        <td>torch.float64</td>\n",
    "        <td>torch.double</td>\n",
    "        <td>DoubleTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>16-bit floating point</td>\n",
    "        <td>torch.float16</td>\n",
    "        <td>torch.half</td>\n",
    "        <td>HalfTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>8-bit integer (signed)</td>\n",
    "        <td>torch.int8</td>\n",
    "        <td></td>\n",
    "        <td>CharTensor</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>8-bit integer (unsigned)</td>\n",
    "        <td>torch.uint8</td>\n",
    "        <td></td>\n",
    "        <td>ByteTensor</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c1488b-8e4f-484b-a8e3-ddc7fd383fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmat.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e4090d-dc74-4952-b818-e2d9cb7cc897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.from_numpy(np.array(np.random.random()).astype('int64'))\n",
    "print(z)\n",
    "z.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077731c-8a64-4dc8-b22c-a9afbb1e0f49",
   "metadata": {},
   "source": [
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.from_numpy'><strong><tt>torch.from_numpy()</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.as_tensor'><strong><tt>torch.as_tensor()</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.tensor'><strong><tt>torch.tensor()</tt></strong></a><br>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "There are a number of different functions available for <a href='https://pytorch.org/docs/stable/torch.html#creation-ops'>creating tensors</a>. When using <a href='https://pytorch.org/docs/stable/torch.html#torch.from_numpy'><strong><tt>torch.from_numpy()</tt></strong></a> and <a href='https://pytorch.org/docs/stable/torch.html#torch.as_tensor'><strong><tt>torch.as_tensor()</tt></strong></a>, the PyTorch tensor and the source NumPy array share the same memory. This means that changes to one affect the other. However, the <a href='https://pytorch.org/docs/stable/torch.html#torch.tensor'><strong><tt>torch.tensor()</tt></strong></a> function always makes a copy.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0465b8db-4e5f-4569-8b6c-1ac4f480270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Using torch.from_numpy()\n",
    "arr = np.arange(0,5)\n",
    "t = torch.from_numpy(arr)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78525e80-7b55-44c8-890c-7abe5254a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1, 77,  3,  4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr[2] = 77\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac76027-c825-4fe7-b388-08c14378cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Using torch.tensor()\n",
    "arr = np.arange(0,5)\n",
    "t = torch.tensor(arr)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ce20f1-80ae-417d-bc7b-1cc03b7ea38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr[2] = 77\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8a782-e7b6-4227-b7a7-09506eb91212",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>2. Creating tensors from scratch</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <strong>Uninitialized tensors with</strong> <tt>.empty()</tt> <br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.empty'><strong><tt>torch.empty()</tt></strong></a> returns an <em>uninitialized</em> tensor. Essentially a block of memory is allocated according to the size of the tensor, and any values already sitting in the block are returned. This is similar to the behavior of <tt>numpy.empty()</tt>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8519f3a8-3b91-4d79-9d93-bd4bd160c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a959a3-0b37-4dcd-843d-af7838a92d7a",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Initialized tensors with <tt>.zeros()</tt> and <tt>.ones()</tt></h4>\n",
    "\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.zeros'><strong><tt>torch.zeros(size)</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.ones'><strong><tt>torch.ones(size)</tt></strong></a><br>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "It's a good idea to pass in the intended dtype.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "148eb907-cb56-4478-805a-cfe433abbf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4, 3, dtype=torch.int64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef515e0b-cb81-4523-a3ce-ef2c487f14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(4, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8adef-aa11-44cd-b541-37b1b6278bfc",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Tensors from ranges</h4>\n",
    "\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.arange'><strong><tt>torch.arange(start,end,step)</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.linspace'><strong><tt>torch.linspace(start,end,steps)</tt></strong></a><br>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Note that with <tt>.arange()</tt>, <tt>end</tt> is exclusive, while with <tt>linspace()</tt>, <tt>end</tt> is inclusive.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa1cbae-8e72-4ef1-b506-eb21eec08d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2,  4],\n",
      "        [ 6,  8, 10],\n",
      "        [12, 14, 16]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,18,2).reshape(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219ddbe0-353a-4b95-b3a1-6642619c83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.6364,  3.2727,  4.9091],\n",
      "        [ 6.5455,  8.1818,  9.8182, 11.4545],\n",
      "        [13.0909, 14.7273, 16.3636, 18.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0,18,12).reshape(3,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db11888-71d6-4e57-a000-191e5995587d",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Tensors from data</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<tt>torch.tensor()</tt> will choose the dtype based on incoming data:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2af41ff-f632-43f0-b5c2-5f8d459b9521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "torch.int64\n",
      "torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.type())\n",
    "#changing datatypes\n",
    "x.type(torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af892b9-850f-46f2-933d-21006b2a5c3d",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "You can also pass the dtype in as an argument. For a list of dtypes visit <a href=\"https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype\">https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58c844b4-25c8-42af-b6e9-6d849102bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8,  9, -3], dtype=torch.int32)\n",
      "torch.int32\n",
      "torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([8,9,-3], dtype=torch.int)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b44b29-f431-4284-9182-0b9e0fafd3e3",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Changing the dtype of existing tensors</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Don't be tempted to use <tt>x = torch.tensor(x, dtype=torch.type)</tt> as it will raise an error about improper use of tensor cloning.<br>\n",
    "Instead, use the tensor <tt>.type()</tt> method.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd87d3b-78fe-47a7-b3c5-1b4e6207cbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385157b0-f5d2-4594-bb96-f850527aa2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: torch.IntTensor\n",
      "New: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print('Old:', x.type())\n",
    "\n",
    "x = x.type(torch.int64)\n",
    "\n",
    "print('New:', x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a681a3-3860-4067-9fd5-84b396724ac5",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Random number tensor</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.rand'><strong><tt>torch.rand(size)</tt></strong></a> returns random samples from a uniform distribution over [0, 1)<br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.randn'><strong><tt>torch.randn(size)</tt></strong></a> returns samples from the \"standard normal\" distribution [σ = 1]<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Unlike <tt>rand</tt> which is uniform, values closer to zero are more likely to appear.<br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.randint'><strong><tt>torch.randint(low,high,size)</tt></strong></a> returns random integers from low (inclusive) to high (exclusive)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ca2ff33-8295-42bf-b70a-e76133785ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6671, 0.7989, 0.0904],\n",
      "        [0.1503, 0.0468, 0.1173],\n",
      "        [0.9687, 0.8473, 0.4124],\n",
      "        [0.8930, 0.2437, 0.3226]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0efc5fcc-909d-4e9a-8a58-5ccf0521940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5368, -0.0475,  0.7608],\n",
      "        [-0.1866,  0.6753, -0.8869],\n",
      "        [ 1.0618, -2.0881,  0.0266],\n",
      "        [ 1.2814, -1.7819, -0.6486]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4af2e65-0c89-4d56-a2c6-21289ac8d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4],\n",
      "        [0, 1, 0],\n",
      "        [1, 2, 3],\n",
      "        [4, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 5, (4, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a75d66-354f-4739-b2ac-3a0259d4b31d",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Random number tensors that follow the input size</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.rand_like'><strong><tt>torch.rand_like(input)</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.randn_like'><strong><tt>torch.randn_like(input)</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.randint_like'><strong><tt>torch.randint_like(input,low,high)</tt></strong></a><br> these return random number tensors with the same size as <tt>input</tt>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8453057-69fd-4687-8ec5-3daec038bc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0b0cb13-3dde-408b-a365-de1b69a609c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0275, -1.5322, -1.0815,  0.0945,  0.3136],\n",
      "        [ 0.5034, -0.4533, -0.6120,  0.2258, -0.4032]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.randn_like(x)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98b36f-4b79-4d12-8b0b-7c8309353d8c",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "The same syntax can be used with<br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.zeros_like'><strong><tt>torch.zeros_like(input)</tt></strong></a><br>\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.ones_like'><strong><tt>torch.ones_like(input)</tt></strong></a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "736086f0-7cba-486a-842e-aa1917a87076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones_like(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ac60052-12aa-4ff0-b3a3-8d3abf95cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x4 = torch.zeros_like(x3)\n",
    "print(x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6663d84-0a98-4b0b-8337-5153ebe13372",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Setting the random seed</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<a href='https://pytorch.org/docs/stable/torch.html#torch.manual_seed'><strong><tt>torch.manual_seed(int)</tt></strong></a> is used to obtain reproducible results\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6192f70-6b6c-44b5-94a3-ee8692e16aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.rand(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0db4f39c-eae2-46eb-b6b9-ec9b9c2f7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.rand(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156207a-e8d6-422b-8def-4fb1b3e98b27",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Tensor attributes</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    Besides <tt>dtype</tt>, we can look at other <a href='https://pytorch.org/docs/stable/tensor_attributes.html'>tensor attributes</a> like <tt>shape</tt>, <tt>device</tt> and <tt>layout</tt>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "339a5a38-d3ce-43ff-b762-4435421e0490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f3b5834-1e74-45dd-96ea-c8ed9bb0d442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()  # equivalent to x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "804c5e14-9d1b-4b48-8fcf-864b1a5cd3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced2536-5b7f-410c-9cbb-05bba0b1fdf2",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    PyTorch supports use of multiple <a href='https://pytorch.org/docs/stable/tensor_attributes.html#torch-device'>devices</a>, harnessing the power of one or more GPUs in addition to the CPU. We won't explore that here, but you should know that operations between tensors can only happen for tensors installed on the same device.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95db23c4-691e-4f18-b51e-393200bf9592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.strided"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a212e-15ed-4709-8c39-b09384995cd2",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">PyTorch has a class to hold the <a href='https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.layout'>memory layout</a> option. The default setting of <a href='https://en.wikipedia.org/wiki/Stride_of_an_array'>strided</a> will suit our purposes throughout the course.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d3899-d9ae-41f6-bfbd-76646a48e984",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>3. Indexing and Slicing</strong></h4>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Extracting specific values from a tensor works just the same as with NumPy arrays.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deb8a3bb-a15a-4403-aeef-1e960a1da269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).reshape(3,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "852dbd53-26dc-4b14-aa8e-d5f61dc902dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the right hand column values\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d1d2d6f-be39-4843-8f44-6eb4cbade658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the right hand column as a (3,1) slice\n",
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f8bad-d33b-4882-9793-3fcfb564a6e9",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>4. Reshape tensors with <tt>.view()</tt></strong></h4>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view'><strong><tt>view()</tt></strong></a> and <a href='https://pytorch.org/docs/master/torch.html#torch.reshape'><strong><tt>reshape()</tt></strong></a> do essentially the same thing by returning a reshaped tensor without changing the original tensor in place.<br>\n",
    "There's a good discussion of the differences <a href='https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch'>here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3257203-a03c-456b-be95-b71de038750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e400e818-42d3-4efa-a8c1-8d1b35737940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(2,5)\n",
    "y[0, 0] = 5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0789b2a-1c53-479a-b1cf-16193fbe8908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x is changed by changing y, which shares the data...\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f3208d1-092b-4605-93a9-966ccb21a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.reshape(5,2)\n",
    "a[0, 0] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "727c8a36-c0e6-442b-8e22-f0164556e8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([99,  1,  2,  3,  4,  5,  6,  7,  8,  9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d6d71-8af9-426c-95b4-5a4c8021d2ff",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Adopt another tensor's shape with <tt>.view_as()</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    <a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view_as'><strong><tt>view_as(input)</tt></strong></a> only works with tensors that have the same number of elements.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b32286b2-c618-4c61-80a8-4da1a4476e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[99,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.ones((5, 2))\n",
    "x.view_as(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f8f755e-4c57-48dc-829a-7f316de1f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7bdfa6-bd67-4532-8774-48bf6b7a8513",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>5. Tensor Arithmetic</strong></h4>\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "Adding tensors can be performed a few different ways depending on the desired result.<br>\n",
    "As a simple expression:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea162a24-0aff-480a-a74a-e8550a10eb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2dfb4c-8bd3-40c9-8610-b08e8c19f6c3",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    As arguments passed into a torch operation:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a7b92d5-de38-4d65-b280-0ec90b39d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1d2d2-f55b-4da2-8e79-4cb1ec09ab64",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    With an output tensor passed in as an argument:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70976702-ea11-4947-b842-b12d7022019b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(3)\n",
    "torch.add(a, b, out=result)  # equivalent to result=torch.add(a,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a6be8c7-61e1-46f4-af8b-72ecb564cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a.add_(b)  # equivalent to a=torch.add(a,b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69be7c-a437-4160-8b83-8506f0a3a78e",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<strong>NOTE:</strong> Any operation that changes a tensor in-place is post-fixed with an underscore _.\n",
    "    <br>In the above example: <tt>a.add_(b)</tt> changed <tt>a</tt>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6fbc3e-2122-482d-a878-3c837efe30f1",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>Basic Tensor Operations</strong></h4>\n",
    "<center>\n",
    "<table style=\"display: inline-block; font-family: Times New Roman\">\n",
    "    <caption style=\"text-align: center\"><strong>ARITHMETIC</strong></caption>\n",
    "    <tr>\n",
    "        <td><b>Operation</b></td>\n",
    "        <td><b>Function</b></td>\n",
    "        <td><b>Description</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a + b</td>\n",
    "        <td>a.add(b)</td>\n",
    "        <td>element wise addition</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a - b</td>\n",
    "        <td>a.sub(b)</td>\n",
    "        <td>subtraction</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a * b</td>\n",
    "        <td>a.mul(b)</td>\n",
    "        <td>multiplication</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a / b</td>\n",
    "        <td>a.div(b)</td>\n",
    "        <td>division</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a % b</td>\n",
    "        <td>a.fmod(b)</td>\n",
    "        <td>modulo (remainder after division)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>a<sup>b</sup></td>\n",
    "        <td>a.pow(b)</td>\n",
    "        <td>power</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>&nbsp;</td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeedaca-c862-4d68-9347-92580f92be1d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table style=\"display: inline-block; font-family: Times New Roman\">\n",
    "<caption style=\"text-align: center\"><strong>MONOMIAL OPERATIONS</strong></caption>\n",
    "<tr><th>Operation</th><th>Function</th><th>Description</th></tr>\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\n",
    "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>square root</td></tr>\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349ec68-5e99-4965-aad8-7f90ec5af295",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table style=\"display: inline-block; font-family: Times New Roman\">\n",
    "<caption style=\"text-align: center\"><strong>SUMMARY STATISTICS</strong></caption>\n",
    "<tr><th>Operation</th><th>Function</th><th>Description</th></tr>\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\n",
    "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
    "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bb793-3296-4c68-81db-1f94cde75dbe",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<strong>NOTE:</strong>  Most arithmetic operations require float values. Those that do work with integers return integer tensors.<br>\n",
    "For example, <tt>torch.div(a,b)</tt> performs floor division (truncates the decimal) for integer types, and classic division for floats.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd2e31-3231-4137-bd19-1e71fe9843a2",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>6. Dot Products</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "A <a href='https://en.wikipedia.org/wiki/Dot_product'>dot product</a> is the sum of the products of the corresponding entries of two 1D tensors. If the tensors are both vectors, the dot product is given as:<br>\n",
    "<br>\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\n",
    "<br>\n",
    "If the tensors include a column vector, then the dot product is the sum of the result of the multiplied matrices. For example:<br>\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\\\ e \\\\ f \\end{bmatrix} = ad + be + cf$<br><br>\n",
    "Dot products can be expressed as <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> or <tt>a.dot(b)</tt> or <tt>b.dot(a)</tt>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2e6003b-cc9d-4547-9324-b6aade15bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55821a46-8394-45c2-a1ab-eea0eab24932",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "<strong>NOTE:</strong>  There's a slight difference between <tt>torch.dot()</tt> and <tt>numpy.dot()</tt>. While <tt>torch.dot()</tt> only accepts 1D arguments and returns a dot product, <tt>numpy.dot()</tt> also accepts 2D arguments and performs matrix multiplication. We show matrix multiplication below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816df09e-9607-49a2-b70a-96b9ac8abe79",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>7. Matrix Multiplication</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>Matrix multiplication</a> is possible when the number of columns in tensor <strong><tt>A</tt></strong> matches the number of rows in tensor <strong><tt>B</tt></strong>. In this case, the product of tensor <strong><tt>A</tt></strong> with size $(x,y)$ and tensor <strong><tt>B</tt></strong> with size $(y,z)$ results in a tensor of size $(x,z)$\n",
    "<br>\n",
    "$\\begin{bmatrix} a & b & c \\\\\n",
    "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
    "<br>\n",
    "Matrix multiplication can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> or <tt>a.mm(b)</tt> or <tt>a @ b</tt>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2d3ce5e-9102-43b2-a482-257599a827b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n",
      "a x b:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
    "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
    "\n",
    "print('a: ',a.size())\n",
    "print('b: ',b.size())\n",
    "print('a x b: ',torch.mm(a,b).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2c0f87a-58f4-46e2-8fac-0547280599b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd17140f-5778-4dcf-bcf9-971decc9e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f323ed9b-c5de-459c-8fd7-2c5ce28d7263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70796441-e50a-421f-af6a-b2f64c77edac",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\">Matrix multiplication with broadcasting</h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "    Matrix multiplication that involves <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcasting</a> can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> or `a.matmul(b)` or `a @ b`\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7128ac73-c4c7-4898-abe2-7e2d74f34d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(2, 3, 4)\n",
    "t2 = torch.randn(4, 5)\n",
    "\n",
    "print(torch.matmul(t1, t2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29220e-7740-4791-80c9-1683ce97f5e1",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "However, the same operation raises a <tt><strong>RuntimeError</strong></tt> with <tt>torch.mm()</tt>:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24df7290-1f98-4568-bb51-43e9274f25b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7596,  0.7343, -0.6708],\n",
       "        [ 2.7421,  0.5568, -0.8123]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(torch.mm(t1, t2).size())\n",
    "t1 = torch.randn(2, 3)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ad9c1a2-8e20-46e4-8e6f-64f89422a158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1964],\n",
       "        [ 0.8613],\n",
       "        [-1.3682]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.randn(3).reshape(3,1)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5594de4e-42a4-4916-9c3e-29dbab0c77de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4590],\n",
      "        [4.8718]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(t1, t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b912b-5187-4089-8814-cf387995b197",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>8. Additional Operations</strong></h4>\n",
    "<h4 style=\"font-family: Times New Roman\"><strong>&emsp;&emsp;L2 or Euclidean Norm</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "&emsp;&emsp;See <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\n",
    "<br>\n",
    "&emsp;&emsp;The <a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>Euclidian Norm</a> gives the vector norm of $x$ where $x=(x_1,x_2,...,x_n)$.<br>\n",
    "&emsp;&emsp;It is calculated as\n",
    "<br>\n",
    "<br>\n",
    "&emsp;&emsp;${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}}$\n",
    "<br>\n",
    "<br>\n",
    "&emsp;&emsp;When applied to a matrix, <tt>torch.norm()</tt> returns the <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>Frobenius norm</a> by default.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "285f7206-c9dc-4742-82c3-22fe5df42c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.,5.,8.,14.])\n",
    "x.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7080597-97dd-4220-80e5-de9aacbd7eb7",
   "metadata": {},
   "source": [
    "<h4 style=\"font-family: Times New Roman\"><strong>&emsp;&emsp;Number of Elements</strong></h4>\n",
    "\n",
    "<p style=\"font-family:Times New Roman; text-align:justify; font-size:15px\">\n",
    "&emsp;&emsp;See <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\n",
    "<br>\n",
    "&emsp;&emsp;Returns the number of elements in a tensor.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7196cd3d-1d9e-4a97-b66a-bcf2aeb230c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,7)\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31efa9-c178-49f1-8d31-a14beefa346c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-family: Times New Roman\">\n",
    "    <h4><strong>Laboratory Task 5</strong></h4>\n",
    "\n",
    "**1. Perform Standard Imports**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import numpy as np\n",
    "```\n",
    "<br>\n",
    "\n",
    "**2. Create a function called `set_seed()` that accepts `seed: int` as a parameter, this function must return nothing but just set the seed to a certain value.**\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Create a NumPy array called \"arr\" that contains 6 random integers between 0 (inclusive) and 5 (exclusive), call the `set_seed()` function and use `42` as the seed parameter.**\n",
    "\n",
    "<br>\n",
    "\n",
    "**4. Create a tensor \"x\" from the array above**\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Change the dtype of x from `int32` to `int64`**\n",
    "\n",
    "<br>\n",
    "\n",
    "**6. Reshape `x` into a 3x2 tensor** <br> There are several ways to do this.\n",
    "\n",
    "<br>\n",
    "\n",
    "**7. Return the right-hand column of tensor `x`**\n",
    "\n",
    "<br>\n",
    "\n",
    "**8. Without changing x, return a tensor of square values of `x`** <br> There are several ways to do this.\n",
    "\n",
    "<br>\n",
    "\n",
    "**9. Create a tensor `y` with the same number of elements as `x`, that can be matrix-multiplied with `x`** <br> Use PyTorch directly (not NumPy) to create a tensor of random integers between 0 (inclusive) and 5 (exclusive). Use 42 as seed. <br> Think about what shape it should have to permit matrix multiplication.\n",
    "\n",
    "<br>\n",
    "\n",
    "**10. Find the matrix product of `x` and `y`.**\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}